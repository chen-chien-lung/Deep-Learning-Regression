{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "\n",
    "df_train = pd.read_csv('train-v3.csv')\n",
    "df_vad = pd.read_csv('valid-v3.csv')\n",
    "df_test = pd.read_csv('test-v3.csv')\n",
    "# df_pre = pd.concat([df_train, df_vad], axis=0, sort=True)\n",
    "\n",
    "df_train_Y = df_train['price']\n",
    "df_train.drop(['price'], axis=1, inplace=True)\n",
    "df_vad_Y = df_vad['price']\n",
    "df_vad.drop(['price'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureHandling(df_data):\n",
    "    df_data.drop(['id'], axis=1, inplace=True)\n",
    "    \n",
    "    categorical = ['zipcode','waterfront','view','condition']\n",
    "    for var in categorical:\n",
    "        df_data = pd.concat([df_data, pd.get_dummies(df_data[var], prefix=var)], axis=1)\n",
    "        del df_data[var]\n",
    "    \n",
    "    label = ['sqft_living','sqft_lot','sqft_above','sqft_basement','sqft_living15','sqft_lot15','yr_built',\n",
    "             'sale_month','sale_day','bathrooms','bedrooms','floors','grade','yr_renovated','sqft_living',\n",
    "             'sqft_lot','sqft_above','sqft_basement','sqft_living15','sqft_lot15','yr_built','sale_month',\n",
    "             'sale_day','bathrooms','bedrooms','floors','grade','lat','long']\n",
    "    normalize_items = df_data[label].values\n",
    "    normalized_items = preprocessing.scale(normalize_items, with_mean=True,with_std=True,copy=True)\n",
    "    i = 0 \n",
    "    for var in label:\n",
    "        df_data[var] = normalized_items[:,i]\n",
    "        i = i + 1\n",
    "        \n",
    "    return df_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = featureHandling(df_train).to_numpy()\n",
    "val = featureHandling(df_vad).to_numpy()\n",
    "test = featureHandling(df_test).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12967, 99)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12967 samples, validate on 2161 samples\n",
      "Epoch 1/300\n",
      " - 2s - loss: 423175.2851 - mae: 423175.3125 - val_loss: 211566.4498 - val_mae: 211566.4531\n",
      "Epoch 2/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joe3813846/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: val_loss,val_mae,loss,mae\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 221087.0063 - mae: 221086.9844 - val_loss: 208773.8995 - val_mae: 208773.8906\n",
      "Epoch 3/300\n",
      " - 1s - loss: 220087.4089 - mae: 220087.4062 - val_loss: 208526.8249 - val_mae: 208526.8125\n",
      "Epoch 4/300\n",
      " - 1s - loss: 219083.4124 - mae: 219083.4531 - val_loss: 206580.5793 - val_mae: 206580.5781\n",
      "Epoch 5/300\n",
      " - 1s - loss: 217929.8841 - mae: 217929.8750 - val_loss: 205524.7741 - val_mae: 205524.7656\n",
      "Epoch 6/300\n",
      " - 1s - loss: 216839.6096 - mae: 216839.5781 - val_loss: 205053.4406 - val_mae: 205053.4531\n",
      "Epoch 7/300\n",
      " - 1s - loss: 215076.7974 - mae: 215076.7188 - val_loss: 201578.9134 - val_mae: 201578.9219\n",
      "Epoch 8/300\n",
      " - 1s - loss: 211048.1333 - mae: 211048.1562 - val_loss: 196558.8819 - val_mae: 196558.8906\n",
      "Epoch 9/300\n",
      " - 1s - loss: 200010.6362 - mae: 200010.6250 - val_loss: 174105.4476 - val_mae: 174105.4688\n",
      "Epoch 10/300\n",
      " - 1s - loss: 152876.7289 - mae: 152876.7031 - val_loss: 137743.1799 - val_mae: 137743.1562\n",
      "Epoch 11/300\n",
      " - 1s - loss: 126530.1745 - mae: 126530.1875 - val_loss: 115142.6537 - val_mae: 115142.6484\n",
      "Epoch 12/300\n",
      " - 1s - loss: 114057.6738 - mae: 114057.7031 - val_loss: 108188.1832 - val_mae: 108188.1797\n",
      "Epoch 13/300\n",
      " - 1s - loss: 106797.3311 - mae: 106797.3359 - val_loss: 105475.8957 - val_mae: 105475.8906\n",
      "Epoch 14/300\n",
      " - 1s - loss: 101970.1709 - mae: 101970.1953 - val_loss: 98866.3610 - val_mae: 98866.3594\n",
      "Epoch 15/300\n",
      " - 1s - loss: 97973.1511 - mae: 97973.1797 - val_loss: 94854.3855 - val_mae: 94854.3828\n",
      "Epoch 16/300\n",
      " - 1s - loss: 95133.0420 - mae: 95133.0391 - val_loss: 94322.8675 - val_mae: 94322.8750\n",
      "Epoch 17/300\n",
      " - 1s - loss: 95035.3292 - mae: 95035.3438 - val_loss: 91898.7723 - val_mae: 91898.7734\n",
      "Epoch 18/300\n",
      " - 1s - loss: 91344.7023 - mae: 91344.6875 - val_loss: 91640.5783 - val_mae: 91640.5781\n",
      "Epoch 19/300\n",
      " - 1s - loss: 90084.2330 - mae: 90084.2656 - val_loss: 87003.3388 - val_mae: 87003.3359\n",
      "Epoch 20/300\n",
      " - 1s - loss: 88676.3910 - mae: 88676.3672 - val_loss: 88117.1402 - val_mae: 88117.1406\n",
      "Epoch 21/300\n",
      " - 1s - loss: 87045.2393 - mae: 87045.2422 - val_loss: 85912.4625 - val_mae: 85912.4609\n",
      "Epoch 22/300\n",
      " - 1s - loss: 86071.5525 - mae: 86071.5469 - val_loss: 85247.9466 - val_mae: 85247.9453\n",
      "Epoch 23/300\n",
      " - 1s - loss: 85168.1605 - mae: 85168.1641 - val_loss: 82160.0385 - val_mae: 82160.0391\n",
      "Epoch 24/300\n",
      " - 1s - loss: 84392.8999 - mae: 84392.8984 - val_loss: 82130.1377 - val_mae: 82130.1406\n",
      "Epoch 25/300\n",
      " - 1s - loss: 83599.8542 - mae: 83599.8750 - val_loss: 80558.2357 - val_mae: 80558.2344\n",
      "Epoch 26/300\n",
      " - 1s - loss: 83799.3019 - mae: 83799.3125 - val_loss: 81574.6800 - val_mae: 81574.6797\n",
      "Epoch 27/300\n",
      " - 1s - loss: 83611.2619 - mae: 83611.2734 - val_loss: 80156.2164 - val_mae: 80156.2188\n",
      "Epoch 28/300\n",
      " - 1s - loss: 83173.3376 - mae: 83173.3359 - val_loss: 81403.1222 - val_mae: 81403.1172\n",
      "Epoch 29/300\n",
      " - 1s - loss: 82172.9368 - mae: 82172.9531 - val_loss: 79913.7179 - val_mae: 79913.7109\n",
      "Epoch 30/300\n",
      " - 1s - loss: 82247.1286 - mae: 82247.1406 - val_loss: 79836.1487 - val_mae: 79836.1484\n",
      "Epoch 31/300\n",
      " - 1s - loss: 80390.9570 - mae: 80390.9609 - val_loss: 83298.0960 - val_mae: 83298.1016\n",
      "Epoch 32/300\n",
      " - 1s - loss: 80631.9732 - mae: 80631.9688 - val_loss: 77742.7404 - val_mae: 77742.7500\n",
      "Epoch 33/300\n",
      " - 1s - loss: 79886.8180 - mae: 79886.8203 - val_loss: 78670.7616 - val_mae: 78670.7656\n",
      "Epoch 34/300\n",
      " - 1s - loss: 80082.5389 - mae: 80082.5312 - val_loss: 79111.1610 - val_mae: 79111.1641\n",
      "Epoch 35/300\n",
      " - 1s - loss: 79468.5262 - mae: 79468.5234 - val_loss: 76501.1095 - val_mae: 76501.1094\n",
      "Epoch 36/300\n",
      " - 1s - loss: 78463.6069 - mae: 78463.6016 - val_loss: 76241.8932 - val_mae: 76241.8906\n",
      "Epoch 37/300\n",
      " - 1s - loss: 80453.5202 - mae: 80453.5156 - val_loss: 77445.8001 - val_mae: 77445.7969\n",
      "Epoch 38/300\n",
      " - 1s - loss: 77794.0021 - mae: 77794.0000 - val_loss: 75334.1738 - val_mae: 75334.1719\n",
      "Epoch 39/300\n",
      " - 1s - loss: 77721.3755 - mae: 77721.3750 - val_loss: 77317.4401 - val_mae: 77317.4375\n",
      "Epoch 40/300\n",
      " - 1s - loss: 77205.5262 - mae: 77205.5234 - val_loss: 82089.8435 - val_mae: 82089.8516\n",
      "Epoch 41/300\n",
      " - 1s - loss: 78350.8334 - mae: 78350.8359 - val_loss: 75301.5034 - val_mae: 75301.5000\n",
      "Epoch 42/300\n",
      " - 1s - loss: 79172.9754 - mae: 79172.9766 - val_loss: 74960.9808 - val_mae: 74960.9844\n",
      "Epoch 43/300\n",
      " - 1s - loss: 77140.8249 - mae: 77140.8203 - val_loss: 78195.1777 - val_mae: 78195.1797\n",
      "Epoch 44/300\n",
      " - 1s - loss: 78134.5551 - mae: 78134.5625 - val_loss: 76954.7443 - val_mae: 76954.7422\n",
      "Epoch 45/300\n",
      " - 1s - loss: 78328.0604 - mae: 78328.0547 - val_loss: 75992.4973 - val_mae: 75992.4922\n",
      "Epoch 46/300\n",
      " - 1s - loss: 77127.1320 - mae: 77127.1328 - val_loss: 74856.0017 - val_mae: 74856.0078\n",
      "Epoch 47/300\n",
      " - 1s - loss: 75985.7955 - mae: 75985.8125 - val_loss: 76036.7881 - val_mae: 76036.7812\n",
      "Epoch 48/300\n",
      " - 1s - loss: 75907.1004 - mae: 75907.1016 - val_loss: 75349.4784 - val_mae: 75349.4766\n",
      "Epoch 49/300\n",
      " - 1s - loss: 76682.1846 - mae: 76682.1953 - val_loss: 74628.2652 - val_mae: 74628.2656\n",
      "Epoch 50/300\n",
      " - 1s - loss: 77183.5309 - mae: 77183.5312 - val_loss: 75052.6404 - val_mae: 75052.6484\n",
      "Epoch 51/300\n",
      " - 1s - loss: 75055.1344 - mae: 75055.1172 - val_loss: 72757.2041 - val_mae: 72757.1953\n",
      "Epoch 52/300\n",
      " - 1s - loss: 75336.2685 - mae: 75336.2891 - val_loss: 73142.3098 - val_mae: 73142.3047\n",
      "Epoch 53/300\n",
      " - 1s - loss: 74917.0010 - mae: 74916.9922 - val_loss: 79598.7496 - val_mae: 79598.7500\n",
      "Epoch 54/300\n",
      " - 1s - loss: 74950.1615 - mae: 74950.1641 - val_loss: 72775.7250 - val_mae: 72775.7266\n",
      "Epoch 55/300\n",
      " - 1s - loss: 77005.8818 - mae: 77005.8906 - val_loss: 73636.4114 - val_mae: 73636.4062\n",
      "Epoch 56/300\n",
      " - 1s - loss: 77851.7701 - mae: 77851.7812 - val_loss: 73142.8414 - val_mae: 73142.8438\n",
      "Epoch 57/300\n",
      " - 1s - loss: 76287.5722 - mae: 76287.5781 - val_loss: 74912.1500 - val_mae: 74912.1406\n",
      "Epoch 58/300\n",
      " - 1s - loss: 78171.9536 - mae: 78171.9531 - val_loss: 76418.1084 - val_mae: 76418.1016\n",
      "Epoch 59/300\n",
      " - 1s - loss: 74879.4415 - mae: 74879.4453 - val_loss: 73654.2511 - val_mae: 73654.2500\n",
      "Epoch 60/300\n",
      " - 1s - loss: 75468.8148 - mae: 75468.8047 - val_loss: 73844.8845 - val_mae: 73844.8828\n",
      "Epoch 61/300\n",
      " - 1s - loss: 76102.8111 - mae: 76102.8281 - val_loss: 75512.4295 - val_mae: 75512.4297\n",
      "Epoch 62/300\n",
      " - 1s - loss: 74738.7112 - mae: 74738.7109 - val_loss: 75837.8521 - val_mae: 75837.8594\n",
      "Epoch 63/300\n",
      " - 1s - loss: 75608.3378 - mae: 75608.3516 - val_loss: 71643.6105 - val_mae: 71643.6016\n",
      "Epoch 64/300\n",
      " - 1s - loss: 74643.7156 - mae: 74643.7109 - val_loss: 75398.9988 - val_mae: 75399.0000\n",
      "Epoch 65/300\n",
      " - 1s - loss: 74199.7628 - mae: 74199.7500 - val_loss: 72744.8183 - val_mae: 72744.8125\n",
      "Epoch 66/300\n",
      " - 1s - loss: 73947.8878 - mae: 73947.8906 - val_loss: 73530.5755 - val_mae: 73530.5781\n",
      "Epoch 67/300\n",
      " - 1s - loss: 75515.7092 - mae: 75515.7188 - val_loss: 71735.4817 - val_mae: 71735.4766\n",
      "Epoch 68/300\n",
      " - 1s - loss: 73774.9136 - mae: 73774.9297 - val_loss: 72410.9663 - val_mae: 72410.9688\n",
      "Epoch 69/300\n",
      " - 1s - loss: 74925.7381 - mae: 74925.7344 - val_loss: 72683.4618 - val_mae: 72683.4609\n",
      "Epoch 70/300\n",
      " - 1s - loss: 75206.4021 - mae: 75206.4062 - val_loss: 73435.7007 - val_mae: 73435.6953\n",
      "Epoch 71/300\n",
      " - 1s - loss: 75599.1329 - mae: 75599.1484 - val_loss: 71784.2171 - val_mae: 71784.2109\n",
      "Epoch 72/300\n",
      " - 1s - loss: 73593.5018 - mae: 73593.5078 - val_loss: 72432.9229 - val_mae: 72432.9219\n",
      "Epoch 73/300\n",
      " - 1s - loss: 74405.5523 - mae: 74405.5547 - val_loss: 72974.0427 - val_mae: 72974.0469\n",
      "Epoch 74/300\n",
      " - 1s - loss: 74372.9685 - mae: 74372.9609 - val_loss: 78299.5075 - val_mae: 78299.5000\n",
      "Epoch 75/300\n",
      " - 1s - loss: 74151.0518 - mae: 74151.0547 - val_loss: 77406.7768 - val_mae: 77406.7656\n",
      "Epoch 76/300\n",
      " - 1s - loss: 73622.4238 - mae: 73622.4141 - val_loss: 77710.4248 - val_mae: 77710.4219\n",
      "Epoch 77/300\n",
      " - 1s - loss: 74097.6947 - mae: 74097.6953 - val_loss: 74228.3168 - val_mae: 74228.3203\n",
      "Epoch 78/300\n",
      " - 1s - loss: 74171.7493 - mae: 74171.7344 - val_loss: 86597.9158 - val_mae: 86597.9141\n",
      "Epoch 79/300\n",
      " - 1s - loss: 74997.6668 - mae: 74997.6406 - val_loss: 77128.5815 - val_mae: 77128.5781\n",
      "Epoch 80/300\n",
      " - 1s - loss: 73742.6383 - mae: 73742.6484 - val_loss: 70414.6320 - val_mae: 70414.6328\n",
      "Epoch 81/300\n",
      " - 1s - loss: 73956.4206 - mae: 73956.4219 - val_loss: 75351.2838 - val_mae: 75351.2812\n",
      "Epoch 82/300\n",
      " - 1s - loss: 73920.0821 - mae: 73920.0781 - val_loss: 72597.2962 - val_mae: 72597.2969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/300\n",
      " - 1s - loss: 74525.3951 - mae: 74525.3984 - val_loss: 77663.4601 - val_mae: 77663.4688\n",
      "Epoch 84/300\n",
      " - 1s - loss: 73321.7328 - mae: 73321.7500 - val_loss: 72943.7270 - val_mae: 72943.7344\n",
      "Epoch 85/300\n",
      " - 1s - loss: 74289.0935 - mae: 74289.1016 - val_loss: 73929.0718 - val_mae: 73929.0781\n",
      "Epoch 86/300\n",
      " - 1s - loss: 74743.3780 - mae: 74743.3750 - val_loss: 75682.3455 - val_mae: 75682.3516\n",
      "Epoch 87/300\n",
      " - 1s - loss: 74181.0539 - mae: 74181.0625 - val_loss: 70924.2546 - val_mae: 70924.2500\n",
      "Epoch 88/300\n",
      " - 1s - loss: 73057.2220 - mae: 73057.2500 - val_loss: 70266.3114 - val_mae: 70266.3125\n",
      "Epoch 89/300\n",
      " - 1s - loss: 73736.1560 - mae: 73736.1406 - val_loss: 75941.7146 - val_mae: 75941.7266\n",
      "Epoch 90/300\n",
      " - 1s - loss: 74872.3045 - mae: 74872.3125 - val_loss: 70778.9736 - val_mae: 70778.9766\n",
      "Epoch 91/300\n",
      " - 1s - loss: 73114.5107 - mae: 73114.5000 - val_loss: 71617.0490 - val_mae: 71617.0469\n",
      "Epoch 92/300\n",
      " - 1s - loss: 72806.4537 - mae: 72806.4609 - val_loss: 71693.5930 - val_mae: 71693.5938\n",
      "Epoch 93/300\n",
      " - 1s - loss: 72954.6784 - mae: 72954.6641 - val_loss: 70388.9535 - val_mae: 70388.9531\n",
      "Epoch 94/300\n",
      " - 1s - loss: 76578.0419 - mae: 76578.0469 - val_loss: 83169.6422 - val_mae: 83169.6406\n",
      "Epoch 95/300\n",
      " - 1s - loss: 74968.6202 - mae: 74968.6250 - val_loss: 76089.3868 - val_mae: 76089.3828\n",
      "Epoch 96/300\n",
      " - 1s - loss: 72529.7581 - mae: 72529.7656 - val_loss: 74545.8681 - val_mae: 74545.8828\n",
      "Epoch 97/300\n",
      " - 1s - loss: 73024.8579 - mae: 73024.8516 - val_loss: 70172.7929 - val_mae: 70172.7891\n",
      "Epoch 98/300\n",
      " - 1s - loss: 73994.6064 - mae: 73994.6094 - val_loss: 79017.7394 - val_mae: 79017.7266\n",
      "Epoch 99/300\n",
      " - 1s - loss: 73567.2262 - mae: 73567.2266 - val_loss: 72787.5316 - val_mae: 72787.5312\n",
      "Epoch 100/300\n",
      " - 1s - loss: 72610.7869 - mae: 72610.7734 - val_loss: 79096.2729 - val_mae: 79096.2734\n",
      "Epoch 101/300\n",
      " - 1s - loss: 74993.6371 - mae: 74993.6250 - val_loss: 72946.1781 - val_mae: 72946.1875\n",
      "Epoch 102/300\n",
      " - 1s - loss: 72860.3923 - mae: 72860.3984 - val_loss: 71571.5042 - val_mae: 71571.5078\n",
      "Epoch 103/300\n",
      " - 1s - loss: 73629.9877 - mae: 73629.9766 - val_loss: 73007.2550 - val_mae: 73007.2578\n",
      "Epoch 104/300\n",
      " - 1s - loss: 73453.3738 - mae: 73453.3672 - val_loss: 77172.0184 - val_mae: 77172.0312\n",
      "Epoch 105/300\n",
      " - 1s - loss: 74443.5007 - mae: 74443.5000 - val_loss: 78392.0002 - val_mae: 78392.0000\n",
      "Epoch 106/300\n",
      " - 1s - loss: 72346.9272 - mae: 72346.9375 - val_loss: 70767.6536 - val_mae: 70767.6484\n",
      "Epoch 107/300\n",
      " - 1s - loss: 73353.3339 - mae: 73353.3203 - val_loss: 71897.3540 - val_mae: 71897.3438\n",
      "Epoch 108/300\n",
      " - 1s - loss: 74355.5199 - mae: 74355.5000 - val_loss: 70271.8209 - val_mae: 70271.8281\n",
      "Epoch 109/300\n",
      " - 1s - loss: 72687.7721 - mae: 72687.7656 - val_loss: 74223.0079 - val_mae: 74223.0078\n",
      "Epoch 110/300\n",
      " - 1s - loss: 71419.0178 - mae: 71419.0000 - val_loss: 70907.4516 - val_mae: 70907.4531\n",
      "Epoch 111/300\n",
      " - 1s - loss: 72453.3544 - mae: 72453.3516 - val_loss: 71712.0645 - val_mae: 71712.0703\n",
      "Epoch 112/300\n",
      " - 1s - loss: 74046.1241 - mae: 74046.1250 - val_loss: 76029.2378 - val_mae: 76029.2422\n",
      "Epoch 113/300\n",
      " - 1s - loss: 72319.6942 - mae: 72319.6875 - val_loss: 72006.4324 - val_mae: 72006.4375\n",
      "Epoch 114/300\n",
      " - 1s - loss: 73456.9838 - mae: 73456.9844 - val_loss: 72294.1343 - val_mae: 72294.1328\n",
      "Epoch 115/300\n",
      " - 1s - loss: 74292.9318 - mae: 74292.9219 - val_loss: 71547.0767 - val_mae: 71547.0703\n",
      "Epoch 116/300\n",
      " - 1s - loss: 72639.0295 - mae: 72639.0312 - val_loss: 72988.4078 - val_mae: 72988.4062\n",
      "Epoch 117/300\n",
      " - 1s - loss: 72655.3996 - mae: 72655.4141 - val_loss: 74175.4183 - val_mae: 74175.4141\n",
      "Epoch 118/300\n",
      " - 1s - loss: 71984.2913 - mae: 71984.2969 - val_loss: 70798.4569 - val_mae: 70798.4609\n",
      "Epoch 119/300\n",
      " - 1s - loss: 72556.5249 - mae: 72556.5312 - val_loss: 71975.1499 - val_mae: 71975.1484\n",
      "Epoch 120/300\n",
      " - 1s - loss: 73599.9467 - mae: 73599.9297 - val_loss: 70863.2497 - val_mae: 70863.2500\n",
      "Epoch 121/300\n",
      " - 1s - loss: 72858.0717 - mae: 72858.0625 - val_loss: 75767.2189 - val_mae: 75767.2188\n",
      "Epoch 122/300\n",
      " - 1s - loss: 72832.8673 - mae: 72832.8594 - val_loss: 70939.3491 - val_mae: 70939.3516\n",
      "Epoch 123/300\n",
      " - 1s - loss: 76060.1222 - mae: 76060.1172 - val_loss: 71955.0234 - val_mae: 71955.0234\n",
      "Epoch 124/300\n",
      " - 1s - loss: 71701.2627 - mae: 71701.2578 - val_loss: 69910.1974 - val_mae: 69910.2031\n",
      "Epoch 125/300\n",
      " - 1s - loss: 71706.2003 - mae: 71706.2188 - val_loss: 75057.5886 - val_mae: 75057.5859\n",
      "Epoch 126/300\n",
      " - 1s - loss: 73185.1618 - mae: 73185.1641 - val_loss: 71463.7860 - val_mae: 71463.7891\n",
      "Epoch 127/300\n",
      " - 1s - loss: 72965.8454 - mae: 72965.8594 - val_loss: 70404.1853 - val_mae: 70404.1797\n",
      "Epoch 128/300\n",
      " - 1s - loss: 71346.0259 - mae: 71346.0312 - val_loss: 71185.3521 - val_mae: 71185.3516\n",
      "Epoch 129/300\n",
      " - 1s - loss: 71718.9535 - mae: 71718.9688 - val_loss: 69505.4396 - val_mae: 69505.4375\n",
      "Epoch 130/300\n",
      " - 1s - loss: 73006.9459 - mae: 73006.9453 - val_loss: 70132.2979 - val_mae: 70132.2969\n",
      "Epoch 131/300\n",
      " - 1s - loss: 72273.6690 - mae: 72273.6875 - val_loss: 78302.9527 - val_mae: 78302.9453\n",
      "Epoch 132/300\n",
      " - 1s - loss: 73094.1480 - mae: 73094.1562 - val_loss: 70303.5541 - val_mae: 70303.5547\n",
      "Epoch 133/300\n",
      " - 1s - loss: 72650.5601 - mae: 72650.5469 - val_loss: 71559.6085 - val_mae: 71559.6094\n",
      "Epoch 134/300\n",
      " - 1s - loss: 73377.2112 - mae: 73377.1953 - val_loss: 73524.1143 - val_mae: 73524.1172\n",
      "Epoch 135/300\n",
      " - 1s - loss: 72484.8192 - mae: 72484.8047 - val_loss: 73070.7071 - val_mae: 73070.7031\n",
      "Epoch 136/300\n",
      " - 1s - loss: 71365.0262 - mae: 71365.0312 - val_loss: 71898.4879 - val_mae: 71898.4922\n",
      "Epoch 137/300\n",
      " - 1s - loss: 72027.4308 - mae: 72027.4297 - val_loss: 69789.0049 - val_mae: 69789.0078\n",
      "Epoch 138/300\n",
      " - 1s - loss: 72714.0636 - mae: 72714.0703 - val_loss: 72924.4125 - val_mae: 72924.4141\n",
      "Epoch 139/300\n",
      " - 1s - loss: 72976.6660 - mae: 72976.6641 - val_loss: 70849.0436 - val_mae: 70849.0547\n",
      "Epoch 140/300\n",
      " - 1s - loss: 72901.0043 - mae: 72901.0078 - val_loss: 70101.5281 - val_mae: 70101.5234\n",
      "Epoch 141/300\n",
      " - 1s - loss: 73677.7125 - mae: 73677.7031 - val_loss: 71467.7904 - val_mae: 71467.7969\n",
      "Epoch 142/300\n",
      " - 1s - loss: 74153.2019 - mae: 74153.1875 - val_loss: 73247.3403 - val_mae: 73247.3359\n",
      "Epoch 143/300\n",
      " - 1s - loss: 72256.7125 - mae: 72256.6953 - val_loss: 72833.7474 - val_mae: 72833.7500\n",
      "Epoch 144/300\n",
      " - 1s - loss: 72501.5827 - mae: 72501.5781 - val_loss: 74066.1734 - val_mae: 74066.1797\n",
      "Epoch 145/300\n",
      " - 1s - loss: 74305.3335 - mae: 74305.3359 - val_loss: 75071.4374 - val_mae: 75071.4297\n",
      "Epoch 146/300\n",
      " - 1s - loss: 73682.1402 - mae: 73682.1328 - val_loss: 70786.9106 - val_mae: 70786.9062\n",
      "Epoch 147/300\n",
      " - 1s - loss: 72835.7873 - mae: 72835.7969 - val_loss: 69925.9884 - val_mae: 69925.9844\n",
      "Epoch 148/300\n",
      " - 1s - loss: 72296.1178 - mae: 72296.1250 - val_loss: 75436.6491 - val_mae: 75436.6484\n",
      "Epoch 149/300\n",
      " - 1s - loss: 72021.8660 - mae: 72021.8750 - val_loss: 73395.5844 - val_mae: 73395.5938\n",
      "Epoch 150/300\n",
      " - 1s - loss: 71761.6011 - mae: 71761.6172 - val_loss: 69916.9290 - val_mae: 69916.9297\n",
      "Epoch 151/300\n",
      " - 1s - loss: 71807.6000 - mae: 71807.6094 - val_loss: 69762.4284 - val_mae: 69762.4375\n",
      "Epoch 152/300\n",
      " - 1s - loss: 72161.9350 - mae: 72161.9453 - val_loss: 72585.9477 - val_mae: 72585.9531\n",
      "Epoch 153/300\n",
      " - 1s - loss: 72365.3655 - mae: 72365.3750 - val_loss: 71016.2659 - val_mae: 71016.2734\n",
      "Epoch 154/300\n",
      " - 1s - loss: 72876.2659 - mae: 72876.2656 - val_loss: 73576.3584 - val_mae: 73576.3516\n",
      "Epoch 155/300\n",
      " - 1s - loss: 73124.8434 - mae: 73124.8516 - val_loss: 70333.9026 - val_mae: 70333.9062\n",
      "Epoch 156/300\n",
      " - 1s - loss: 71602.4209 - mae: 71602.4297 - val_loss: 70820.0834 - val_mae: 70820.0859\n",
      "Epoch 157/300\n",
      " - 1s - loss: 72262.6534 - mae: 72262.6562 - val_loss: 80120.9466 - val_mae: 80120.9453\n",
      "Epoch 158/300\n",
      " - 1s - loss: 72586.6117 - mae: 72586.6250 - val_loss: 71094.7981 - val_mae: 71094.7969\n",
      "Epoch 159/300\n",
      " - 1s - loss: 72041.2080 - mae: 72041.1797 - val_loss: 70311.8303 - val_mae: 70311.8359\n",
      "Epoch 160/300\n",
      " - 1s - loss: 72824.1266 - mae: 72824.1250 - val_loss: 70251.8192 - val_mae: 70251.8125\n",
      "Epoch 161/300\n",
      " - 1s - loss: 73976.1945 - mae: 73976.1719 - val_loss: 72169.9059 - val_mae: 72169.9062\n",
      "Epoch 162/300\n",
      " - 1s - loss: 73759.3260 - mae: 73759.3281 - val_loss: 71553.9578 - val_mae: 71553.9609\n",
      "Epoch 163/300\n",
      " - 1s - loss: 73557.4613 - mae: 73557.4766 - val_loss: 72753.2644 - val_mae: 72753.2578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/300\n",
      " - 1s - loss: 72879.2145 - mae: 72879.2109 - val_loss: 79930.9521 - val_mae: 79930.9531\n",
      "Epoch 165/300\n",
      " - 1s - loss: 71880.4523 - mae: 71880.4531 - val_loss: 70472.6797 - val_mae: 70472.6875\n",
      "Epoch 166/300\n",
      " - 1s - loss: 73461.9593 - mae: 73461.9531 - val_loss: 71978.5456 - val_mae: 71978.5469\n",
      "Epoch 167/300\n",
      " - 1s - loss: 73926.9751 - mae: 73926.9922 - val_loss: 70354.4929 - val_mae: 70354.4766\n",
      "Epoch 168/300\n",
      " - 1s - loss: 73040.1726 - mae: 73040.1797 - val_loss: 72740.6009 - val_mae: 72740.6016\n",
      "Epoch 169/300\n",
      " - 1s - loss: 72732.6957 - mae: 72732.6797 - val_loss: 78009.0354 - val_mae: 78009.0391\n",
      "Epoch 170/300\n",
      " - 1s - loss: 72507.6162 - mae: 72507.6094 - val_loss: 69594.9827 - val_mae: 69594.9844\n",
      "Epoch 171/300\n",
      " - 1s - loss: 73737.3067 - mae: 73737.3125 - val_loss: 71599.0264 - val_mae: 71599.0312\n",
      "Epoch 172/300\n",
      " - 1s - loss: 71670.9698 - mae: 71670.9531 - val_loss: 69887.7537 - val_mae: 69887.7578\n",
      "Epoch 173/300\n",
      " - 1s - loss: 72084.1287 - mae: 72084.1328 - val_loss: 70297.4798 - val_mae: 70297.4766\n",
      "Epoch 174/300\n",
      " - 1s - loss: 71473.1296 - mae: 71473.1328 - val_loss: 72618.1683 - val_mae: 72618.1719\n",
      "Epoch 175/300\n",
      " - 1s - loss: 71294.6741 - mae: 71294.6797 - val_loss: 70935.6317 - val_mae: 70935.6250\n",
      "Epoch 176/300\n",
      " - 1s - loss: 71804.8458 - mae: 71804.8594 - val_loss: 71474.6667 - val_mae: 71474.6562\n",
      "Epoch 177/300\n",
      " - 1s - loss: 71571.9290 - mae: 71571.9141 - val_loss: 70000.9212 - val_mae: 70000.9219\n",
      "Epoch 178/300\n",
      " - 1s - loss: 72464.3684 - mae: 72464.3750 - val_loss: 71160.3888 - val_mae: 71160.3984\n",
      "Epoch 179/300\n",
      " - 1s - loss: 73215.9343 - mae: 73215.9297 - val_loss: 71612.0841 - val_mae: 71612.0781\n",
      "Epoch 180/300\n",
      " - 1s - loss: 72764.1460 - mae: 72764.1406 - val_loss: 72217.7918 - val_mae: 72217.8047\n",
      "Epoch 181/300\n",
      " - 1s - loss: 73550.8614 - mae: 73550.8516 - val_loss: 71908.0487 - val_mae: 71908.0391\n",
      "Epoch 182/300\n",
      " - 1s - loss: 72580.7289 - mae: 72580.7266 - val_loss: 71324.1283 - val_mae: 71324.1172\n",
      "Epoch 183/300\n",
      " - 1s - loss: 74411.7671 - mae: 74411.7734 - val_loss: 70353.9412 - val_mae: 70353.9375\n",
      "Epoch 184/300\n",
      " - 1s - loss: 72892.6886 - mae: 72892.6797 - val_loss: 74049.4011 - val_mae: 74049.3984\n",
      "Epoch 185/300\n",
      " - 1s - loss: 72350.5760 - mae: 72350.5703 - val_loss: 70341.8150 - val_mae: 70341.8203\n",
      "Epoch 186/300\n",
      " - 1s - loss: 71770.7789 - mae: 71770.7734 - val_loss: 74051.5888 - val_mae: 74051.5859\n",
      "Epoch 187/300\n",
      " - 1s - loss: 72050.7841 - mae: 72050.7891 - val_loss: 70006.6349 - val_mae: 70006.6328\n",
      "Epoch 188/300\n",
      " - 1s - loss: 72455.7582 - mae: 72455.7500 - val_loss: 78471.6452 - val_mae: 78471.6484\n",
      "Epoch 189/300\n",
      " - 1s - loss: 72158.7385 - mae: 72158.7344 - val_loss: 71213.3019 - val_mae: 71213.3047\n",
      "Epoch 190/300\n",
      " - 1s - loss: 71482.8464 - mae: 71482.8594 - val_loss: 69887.3744 - val_mae: 69887.3672\n",
      "Epoch 191/300\n",
      " - 1s - loss: 72134.4023 - mae: 72134.4141 - val_loss: 70324.2740 - val_mae: 70324.2812\n",
      "Epoch 192/300\n",
      " - 1s - loss: 73391.3455 - mae: 73391.3516 - val_loss: 74932.1469 - val_mae: 74932.1484\n",
      "Epoch 193/300\n",
      " - 1s - loss: 72331.9023 - mae: 72331.9141 - val_loss: 72395.0229 - val_mae: 72395.0312\n",
      "Epoch 194/300\n",
      " - 1s - loss: 72266.7988 - mae: 72266.7969 - val_loss: 78311.0451 - val_mae: 78311.0469\n",
      "Epoch 195/300\n",
      " - 1s - loss: 72823.3781 - mae: 72823.3750 - val_loss: 74382.8537 - val_mae: 74382.8516\n",
      "Epoch 196/300\n",
      " - 1s - loss: 72422.8611 - mae: 72422.8516 - val_loss: 69890.6283 - val_mae: 69890.6172\n",
      "Epoch 197/300\n",
      " - 1s - loss: 73015.7644 - mae: 73015.7656 - val_loss: 70551.7615 - val_mae: 70551.7578\n",
      "Epoch 198/300\n",
      " - 1s - loss: 72167.2228 - mae: 72167.2188 - val_loss: 69606.9428 - val_mae: 69606.9375\n",
      "Epoch 199/300\n",
      " - 1s - loss: 71948.5438 - mae: 71948.5391 - val_loss: 74044.9840 - val_mae: 74044.9844\n",
      "Epoch 200/300\n",
      " - 1s - loss: 73397.3148 - mae: 73397.3281 - val_loss: 69986.4948 - val_mae: 69986.5000\n",
      "Epoch 201/300\n",
      " - 1s - loss: 71956.7887 - mae: 71956.7812 - val_loss: 70951.4950 - val_mae: 70951.4922\n",
      "Epoch 202/300\n",
      " - 1s - loss: 71728.9700 - mae: 71728.9844 - val_loss: 74201.6525 - val_mae: 74201.6484\n",
      "Epoch 203/300\n",
      " - 1s - loss: 72973.4538 - mae: 72973.4688 - val_loss: 73841.3576 - val_mae: 73841.3594\n",
      "Epoch 204/300\n",
      " - 1s - loss: 71852.1958 - mae: 71852.1953 - val_loss: 73194.8519 - val_mae: 73194.8516\n",
      "Epoch 205/300\n",
      " - 1s - loss: 73184.1883 - mae: 73184.2109 - val_loss: 75518.1797 - val_mae: 75518.1797\n",
      "Epoch 206/300\n",
      " - 1s - loss: 71471.9973 - mae: 71471.9922 - val_loss: 73698.9036 - val_mae: 73698.9062\n",
      "Epoch 207/300\n",
      " - 1s - loss: 71733.9466 - mae: 71733.9453 - val_loss: 75188.5155 - val_mae: 75188.5156\n",
      "Epoch 208/300\n",
      " - 1s - loss: 73335.5405 - mae: 73335.5469 - val_loss: 70629.4916 - val_mae: 70629.4844\n",
      "Epoch 209/300\n",
      " - 1s - loss: 72441.5199 - mae: 72441.5078 - val_loss: 78229.0683 - val_mae: 78229.0625\n",
      "Epoch 210/300\n",
      " - 1s - loss: 72815.1722 - mae: 72815.1484 - val_loss: 72376.3302 - val_mae: 72376.3281\n",
      "Epoch 211/300\n",
      " - 1s - loss: 70814.2595 - mae: 70814.2500 - val_loss: 75202.4836 - val_mae: 75202.4844\n",
      "Epoch 212/300\n",
      " - 1s - loss: 72893.0543 - mae: 72893.0547 - val_loss: 70100.7516 - val_mae: 70100.7500\n",
      "Epoch 213/300\n",
      " - 1s - loss: 74467.3786 - mae: 74467.3750 - val_loss: 71495.7637 - val_mae: 71495.7656\n",
      "Epoch 214/300\n",
      " - 1s - loss: 74130.9257 - mae: 74130.9297 - val_loss: 71684.4377 - val_mae: 71684.4375\n",
      "Epoch 215/300\n",
      " - 1s - loss: 72660.8446 - mae: 72660.8438 - val_loss: 73488.1456 - val_mae: 73488.1406\n",
      "Epoch 216/300\n",
      " - 1s - loss: 71824.4283 - mae: 71824.4375 - val_loss: 69967.5303 - val_mae: 69967.5312\n",
      "Epoch 217/300\n",
      " - 1s - loss: 73439.1063 - mae: 73439.0859 - val_loss: 69475.8631 - val_mae: 69475.8594\n",
      "Epoch 218/300\n",
      " - 1s - loss: 71620.6520 - mae: 71620.6406 - val_loss: 70791.4148 - val_mae: 70791.4219\n",
      "Epoch 219/300\n",
      " - 1s - loss: 73112.4026 - mae: 73112.3984 - val_loss: 70056.4602 - val_mae: 70056.4531\n",
      "Epoch 220/300\n",
      " - 1s - loss: 71565.0732 - mae: 71565.0625 - val_loss: 76282.2448 - val_mae: 76282.2422\n",
      "Epoch 221/300\n",
      " - 1s - loss: 73176.3444 - mae: 73176.3594 - val_loss: 70104.1974 - val_mae: 70104.1953\n",
      "Epoch 222/300\n",
      " - 1s - loss: 70867.6036 - mae: 70867.6016 - val_loss: 69936.4100 - val_mae: 69936.4141\n",
      "Epoch 223/300\n",
      " - 1s - loss: 71280.6984 - mae: 71280.6953 - val_loss: 70108.4423 - val_mae: 70108.4375\n",
      "Epoch 224/300\n",
      " - 1s - loss: 71270.7619 - mae: 71270.7812 - val_loss: 70186.0986 - val_mae: 70186.1016\n",
      "Epoch 225/300\n",
      " - 1s - loss: 72140.0079 - mae: 72140.0156 - val_loss: 71795.2349 - val_mae: 71795.2266\n",
      "Epoch 226/300\n",
      " - 1s - loss: 72217.1713 - mae: 72217.1797 - val_loss: 69759.1862 - val_mae: 69759.1875\n",
      "Epoch 227/300\n",
      " - 1s - loss: 72532.2098 - mae: 72532.2266 - val_loss: 71081.1360 - val_mae: 71081.1328\n",
      "Epoch 228/300\n",
      " - 1s - loss: 71280.2907 - mae: 71280.2812 - val_loss: 71909.5928 - val_mae: 71909.5938\n",
      "Epoch 229/300\n",
      " - 1s - loss: 72946.3060 - mae: 72946.2891 - val_loss: 69418.4298 - val_mae: 69418.4297\n",
      "Epoch 230/300\n",
      " - 1s - loss: 72211.9463 - mae: 72211.9531 - val_loss: 72008.4172 - val_mae: 72008.4141\n",
      "Epoch 231/300\n",
      " - 1s - loss: 74008.6378 - mae: 74008.6406 - val_loss: 69356.7662 - val_mae: 69356.7656\n",
      "Epoch 232/300\n",
      " - 1s - loss: 71743.3942 - mae: 71743.3984 - val_loss: 70168.4071 - val_mae: 70168.4141\n",
      "Epoch 233/300\n",
      " - 1s - loss: 72293.1595 - mae: 72293.1406 - val_loss: 74809.2364 - val_mae: 74809.2344\n",
      "Epoch 234/300\n",
      " - 1s - loss: 72642.9425 - mae: 72642.9375 - val_loss: 71950.9483 - val_mae: 71950.9453\n",
      "Epoch 235/300\n",
      " - 1s - loss: 73449.9115 - mae: 73449.8984 - val_loss: 73502.1056 - val_mae: 73502.1016\n",
      "Epoch 236/300\n",
      " - 1s - loss: 71283.8534 - mae: 71283.8594 - val_loss: 73056.0939 - val_mae: 73056.0938\n",
      "Epoch 237/300\n",
      " - 1s - loss: 72836.3948 - mae: 72836.4062 - val_loss: 74262.9874 - val_mae: 74262.9766\n",
      "Epoch 238/300\n",
      " - 1s - loss: 71871.7014 - mae: 71871.6953 - val_loss: 69382.0979 - val_mae: 69382.1016\n",
      "Epoch 239/300\n",
      " - 1s - loss: 72433.9037 - mae: 72433.8906 - val_loss: 73375.6983 - val_mae: 73375.7031\n",
      "Epoch 240/300\n",
      " - 1s - loss: 74201.0219 - mae: 74201.0156 - val_loss: 70426.8342 - val_mae: 70426.8281\n",
      "Epoch 241/300\n",
      " - 1s - loss: 71693.8571 - mae: 71693.8359 - val_loss: 71581.4886 - val_mae: 71581.5000\n",
      "Epoch 242/300\n",
      " - 1s - loss: 72924.2761 - mae: 72924.2891 - val_loss: 74009.4886 - val_mae: 74009.4922\n",
      "Epoch 243/300\n",
      " - 1s - loss: 71602.4763 - mae: 71602.4844 - val_loss: 73523.2581 - val_mae: 73523.2656\n",
      "Epoch 244/300\n",
      " - 1s - loss: 73251.2034 - mae: 73251.2109 - val_loss: 79242.4489 - val_mae: 79242.4453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/300\n",
      " - 1s - loss: 72136.7180 - mae: 72136.7031 - val_loss: 71236.8519 - val_mae: 71236.8516\n",
      "Epoch 246/300\n",
      " - 1s - loss: 72687.3491 - mae: 72687.3438 - val_loss: 69628.3801 - val_mae: 69628.3750\n",
      "Epoch 247/300\n",
      " - 1s - loss: 72654.5019 - mae: 72654.4922 - val_loss: 73412.6528 - val_mae: 73412.6484\n",
      "Epoch 248/300\n",
      " - 1s - loss: 71456.5981 - mae: 71456.5859 - val_loss: 73202.2550 - val_mae: 73202.2578\n",
      "Epoch 249/300\n",
      " - 1s - loss: 74308.2941 - mae: 74308.2812 - val_loss: 74737.5488 - val_mae: 74737.5469\n",
      "Epoch 250/300\n",
      " - 1s - loss: 73281.3567 - mae: 73281.3672 - val_loss: 70634.2654 - val_mae: 70634.2656\n",
      "Epoch 251/300\n",
      " - 1s - loss: 72606.4710 - mae: 72606.4688 - val_loss: 70865.7043 - val_mae: 70865.7031\n",
      "Epoch 252/300\n",
      " - 1s - loss: 71452.3797 - mae: 71452.3906 - val_loss: 70467.0118 - val_mae: 70467.0078\n",
      "Epoch 253/300\n",
      " - 1s - loss: 72149.5040 - mae: 72149.5000 - val_loss: 70919.8908 - val_mae: 70919.8906\n",
      "Epoch 254/300\n",
      " - 1s - loss: 72255.5265 - mae: 72255.5469 - val_loss: 70376.1467 - val_mae: 70376.1406\n",
      "Epoch 255/300\n",
      " - 1s - loss: 71882.9122 - mae: 71882.9219 - val_loss: 73628.6635 - val_mae: 73628.6719\n",
      "Epoch 256/300\n",
      " - 1s - loss: 71713.4391 - mae: 71713.4375 - val_loss: 69547.9444 - val_mae: 69547.9531\n",
      "Epoch 257/300\n",
      " - 1s - loss: 71435.1195 - mae: 71435.1172 - val_loss: 71377.8763 - val_mae: 71377.8750\n",
      "Epoch 258/300\n",
      " - 1s - loss: 72002.5546 - mae: 72002.5391 - val_loss: 72178.5911 - val_mae: 72178.6016\n",
      "Epoch 259/300\n",
      " - 1s - loss: 71688.1311 - mae: 71688.1328 - val_loss: 71187.1718 - val_mae: 71187.1719\n",
      "Epoch 260/300\n",
      " - 1s - loss: 71742.1492 - mae: 71742.1406 - val_loss: 71100.4849 - val_mae: 71100.4766\n",
      "Epoch 261/300\n",
      " - 1s - loss: 71480.2223 - mae: 71480.2188 - val_loss: 71994.4671 - val_mae: 71994.4688\n",
      "Epoch 262/300\n",
      " - 1s - loss: 72370.2932 - mae: 72370.2812 - val_loss: 70282.6266 - val_mae: 70282.6250\n",
      "Epoch 263/300\n",
      " - 1s - loss: 73723.4318 - mae: 73723.4219 - val_loss: 70474.5604 - val_mae: 70474.5469\n",
      "Epoch 264/300\n",
      " - 1s - loss: 71484.4367 - mae: 71484.4375 - val_loss: 74097.0464 - val_mae: 74097.0469\n",
      "Epoch 265/300\n",
      " - 1s - loss: 71782.0147 - mae: 71782.0312 - val_loss: 72600.2961 - val_mae: 72600.2969\n",
      "Epoch 266/300\n",
      " - 1s - loss: 72861.1080 - mae: 72861.1172 - val_loss: 70242.5902 - val_mae: 70242.5859\n",
      "Epoch 267/300\n",
      " - 1s - loss: 71925.5042 - mae: 71925.5000 - val_loss: 78249.6677 - val_mae: 78249.6719\n",
      "Epoch 268/300\n",
      " - 1s - loss: 73028.5198 - mae: 73028.5234 - val_loss: 73393.0701 - val_mae: 73393.0625\n",
      "Epoch 269/300\n",
      " - 1s - loss: 71165.4058 - mae: 71165.4219 - val_loss: 70009.4598 - val_mae: 70009.4609\n",
      "Epoch 270/300\n",
      " - 1s - loss: 71373.5098 - mae: 71373.5000 - val_loss: 69864.0725 - val_mae: 69864.0703\n",
      "Epoch 271/300\n",
      " - 1s - loss: 71404.2811 - mae: 71404.2891 - val_loss: 69598.4380 - val_mae: 69598.4375\n",
      "Epoch 272/300\n",
      " - 1s - loss: 71750.8559 - mae: 71750.8438 - val_loss: 70583.1816 - val_mae: 70583.1797\n",
      "Epoch 273/300\n",
      " - 1s - loss: 71911.4954 - mae: 71911.4922 - val_loss: 69650.0556 - val_mae: 69650.0547\n",
      "Epoch 274/300\n",
      " - 1s - loss: 72893.6535 - mae: 72893.6562 - val_loss: 70411.8947 - val_mae: 70411.8906\n",
      "Epoch 275/300\n",
      " - 1s - loss: 72119.2178 - mae: 72119.2109 - val_loss: 71887.2912 - val_mae: 71887.2891\n",
      "Epoch 276/300\n",
      " - 1s - loss: 72578.3966 - mae: 72578.3828 - val_loss: 74307.6147 - val_mae: 74307.6172\n",
      "Epoch 277/300\n",
      " - 1s - loss: 73235.7415 - mae: 73235.7344 - val_loss: 72337.6255 - val_mae: 72337.6250\n",
      "Epoch 278/300\n",
      " - 1s - loss: 71779.3856 - mae: 71779.3828 - val_loss: 73647.9054 - val_mae: 73647.9141\n",
      "Epoch 279/300\n",
      " - 1s - loss: 72135.9674 - mae: 72135.9609 - val_loss: 71592.0045 - val_mae: 71592.0000\n",
      "Epoch 280/300\n",
      " - 1s - loss: 72175.4843 - mae: 72175.4844 - val_loss: 70716.8121 - val_mae: 70716.8125\n",
      "Epoch 281/300\n",
      " - 1s - loss: 72501.7762 - mae: 72501.7969 - val_loss: 78473.0260 - val_mae: 78473.0234\n",
      "Epoch 282/300\n",
      " - 1s - loss: 72131.6888 - mae: 72131.6797 - val_loss: 69820.9973 - val_mae: 69821.0000\n",
      "Epoch 283/300\n",
      " - 1s - loss: 71929.0767 - mae: 71929.0938 - val_loss: 76180.3904 - val_mae: 76180.3828\n",
      "Epoch 284/300\n",
      " - 1s - loss: 72463.1629 - mae: 72463.1484 - val_loss: 70237.5773 - val_mae: 70237.5703\n",
      "Epoch 285/300\n",
      " - 1s - loss: 71989.1394 - mae: 71989.1406 - val_loss: 72822.5393 - val_mae: 72822.5469\n",
      "Epoch 286/300\n",
      " - 1s - loss: 71586.1235 - mae: 71586.1250 - val_loss: 72211.0185 - val_mae: 72211.0234\n",
      "Epoch 287/300\n",
      " - 1s - loss: 71306.1626 - mae: 71306.1797 - val_loss: 71440.8530 - val_mae: 71440.8594\n",
      "Epoch 288/300\n",
      " - 1s - loss: 71702.4463 - mae: 71702.4531 - val_loss: 73590.9084 - val_mae: 73590.9062\n",
      "Epoch 289/300\n",
      " - 1s - loss: 71680.3571 - mae: 71680.3672 - val_loss: 69415.0392 - val_mae: 69415.0391\n",
      "Epoch 290/300\n",
      " - 1s - loss: 72983.6262 - mae: 72983.6406 - val_loss: 69933.4046 - val_mae: 69933.4062\n",
      "Epoch 291/300\n",
      " - 1s - loss: 71091.3459 - mae: 71091.3594 - val_loss: 69716.2938 - val_mae: 69716.3047\n",
      "Epoch 292/300\n",
      " - 1s - loss: 72795.9198 - mae: 72795.9141 - val_loss: 75385.3827 - val_mae: 75385.3828\n",
      "Epoch 293/300\n",
      " - 1s - loss: 71451.6896 - mae: 71451.6953 - val_loss: 71901.8042 - val_mae: 71901.8047\n",
      "Epoch 294/300\n",
      " - 1s - loss: 73147.1044 - mae: 73147.1016 - val_loss: 72603.6984 - val_mae: 72603.6875\n",
      "Epoch 295/300\n",
      " - 1s - loss: 72298.5825 - mae: 72298.5781 - val_loss: 70997.9182 - val_mae: 70997.9141\n",
      "Epoch 296/300\n",
      " - 1s - loss: 71822.6775 - mae: 71822.6797 - val_loss: 71921.2031 - val_mae: 71921.2031\n",
      "Epoch 297/300\n",
      " - 1s - loss: 71025.2508 - mae: 71025.2500 - val_loss: 75713.2860 - val_mae: 75713.2812\n",
      "Epoch 298/300\n",
      " - 1s - loss: 71208.9326 - mae: 71208.9453 - val_loss: 69773.5993 - val_mae: 69773.6016\n",
      "Epoch 299/300\n",
      " - 1s - loss: 71221.4142 - mae: 71221.4219 - val_loss: 70676.3885 - val_mae: 70676.3906\n",
      "Epoch 300/300\n",
      " - 1s - loss: 71636.8200 - mae: 71636.8203 - val_loss: 71146.7621 - val_mae: 71146.7656\n"
     ]
    }
   ],
   "source": [
    "def build_Model(x_size, y_size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=8,input_dim=x_size.shape[1], kernel_initializer='normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=150, kernel_initializer='normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=128, kernel_initializer='normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=150, kernel_initializer='normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=128, kernel_initializer='normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=128, kernel_initializer='normal'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(units=8, kernel_initializer='normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=y_size, kernel_initializer='normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='MAE',\n",
    "        optimizer='adam',\n",
    "        metrics=['mae'])\n",
    "    return(model)\n",
    "\n",
    "model = build_Model(train, 1)\n",
    "\n",
    "epochs = 300\n",
    "batch_size = 128\n",
    "\n",
    "keras_callbacks = [\n",
    "    EarlyStopping(monitor='val_mae', patience=20, verbose=0)\n",
    "]\n",
    "\n",
    "model_history = model.fit(train, df_train_Y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=2, \n",
    "    validation_data=(val, df_vad_Y),\n",
    "    callbacks=keras_callbacks,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264.62393900136937\n"
     ]
    }
   ],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_absolute_error(y, y_pred))\n",
    "\n",
    "train_predict = model.predict(train)\n",
    "print(rmsle(df_train_Y, train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = model_history.history\n",
    "# loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(val_loss_values)+1)\n",
    "# plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = model.predict(test)\n",
    "submissions = pd.DataFrame({\"id\": list(range(1, len(test_predict)+1)),\n",
    "                           \"price\": test_predict[:,0]})\n",
    "submissions.to_csv(\"submissions_DNN.csv\", index = False, header = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
